{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 文本摘要"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# !export https_proxy=http://127.0.0.1:7890 http_proxy=http://127.0.0.1:7890 all_proxy=socks5://127.0.0.1:7890"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install pytorch_lightning\n",
    "# %pip install rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /Users/wangfiox/.cache/jieba.cache\n",
      "Loading model cost 0.365 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "from transformers import PegasusForConditionalGeneration\n",
    "from tokenizers_pegasus import PegasusTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PegasusForConditionalGeneration.from_pretrained(\n",
    "    \"IDEA-CCNL/Randeng-Pegasus-523M-Summary-Chinese-V1\"\n",
    ")\n",
    "\n",
    "tokenizer = PegasusTokenizer.from_pretrained(\n",
    "    \"IDEA-CCNL/Randeng-Pegasus-523M-Summary-Chinese-V1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PegasusForConditionalGeneration(\n",
      "  (model): PegasusModel(\n",
      "    (shared): Embedding(50002, 1024, padding_idx=0)\n",
      "    (encoder): PegasusEncoder(\n",
      "      (embed_tokens): Embedding(50002, 1024, padding_idx=0)\n",
      "      (embed_positions): PegasusSinusoidalPositionalEmbedding(1024, 1024)\n",
      "      (layers): ModuleList(\n",
      "        (0-15): 16 x PegasusEncoderLayer(\n",
      "          (self_attn): PegasusAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (activation_fn): ReLU()\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (decoder): PegasusDecoder(\n",
      "      (embed_tokens): Embedding(50002, 1024, padding_idx=0)\n",
      "      (embed_positions): PegasusSinusoidalPositionalEmbedding(1024, 1024)\n",
      "      (layers): ModuleList(\n",
      "        (0-15): 16 x PegasusDecoderLayer(\n",
      "          (self_attn): PegasusAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (activation_fn): ReLU()\n",
      "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (encoder_attn): PegasusAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (lm_head): Linear(in_features=1024, out_features=50002, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'自由式滑雪女子坡面障碍技巧决赛谷爱凌摘银'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"在北京冬奥会自由式滑雪女子坡面障碍技巧决赛中，中国选手谷爱凌夺得银牌。祝贺谷爱凌！今天上午，自由式滑雪女子坡面障碍技巧决赛举行。决赛分三轮进行，取选手最佳成绩排名决出奖牌。第一跳，中国选手谷爱凌获得69.90分。在12位选手中排名第三。完成动作后，谷爱凌又扮了个鬼脸，甚是可爱。第二轮中，谷爱凌在道具区第三个障碍处失误，落地时摔倒。获得16.98分。网友：摔倒了也没关系，继续加油！在第二跳失误摔倒的情况下，谷爱凌顶住压力，第三跳稳稳发挥，流畅落地！获得86.23分！此轮比赛，共12位选手参赛，谷爱凌第10位出场。网友：看比赛时我比谷爱凌紧张，加油！\"\n",
    "inputs = tokenizer(\n",
    "    text, max_length=1024, truncation=True, return_tensors=\"pt\"\n",
    ")  # 添加了 truncation=True\n",
    "\n",
    "# Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
    "\n",
    "\n",
    "# Generate Summary\n",
    "summary_ids = model.generate(inputs[\"input_ids\"])\n",
    "tokenizer.batch_decode(\n",
    "    summary_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
    ")[0]\n",
    "\n",
    "# model Output: 自由式滑雪女子坡面障碍技巧决赛谷爱凌摘银"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_text(text, max_length=1024, num_beams=4, length_penalty=2.0, max_length_output=150):\n",
    "    \"\"\"\n",
    "    用输入的模型和分词器生成输入文本的摘要。\n",
    "    参数：\n",
    "        - text (str): 要生成摘要的输入文本。\n",
    "    \"\"\"\n",
    "    \n",
    "    inputs = tokenizer(text, max_length=max_length, truncation=True, return_tensors=\"pt\")\n",
    "    \n",
    "    # Generate summary with beam search\n",
    "    summary_ids = model.generate(\n",
    "        inputs[\"input_ids\"], \n",
    "        num_beams=num_beams, \n",
    "        length_penalty=length_penalty, \n",
    "        max_length=max_length_output, \n",
    "        no_repeat_ngram_size=3\n",
    "    )\n",
    "    \n",
    "    return tokenizer.batch_decode(summary_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "清华大学深圳国际研究生院2016年6月16日清深宣讲预报名\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "【清深宣讲预报名】[欢兔喝彩]@所有人 清华大学深圳国际研究生院招生宣讲： 1. 计算机科学与技术项目介绍 2. 数据科学与技术项目介绍 3. 来自以上两个专业的师兄师姐分享申请经验 时间：6月16日（周五）下午 地点后续通知 各位同学，清华深研院本周五将面向我们学院的同学们进行宣讲，内容包含保研（含夏令营）及考研（他们考408）的相关信息。据了解，清深与我们专业相关的有两个计算机科学与技术和数据科学与技术两个方向，他们的学生需求很大，也表示非常喜欢我们的同学，欢迎同学们能够申请和报考。所以，有意向保研或考研到清深，或者还在观望的同学都能去看一看、听一听，多多了解。预报名链接：[清深宣讲预报名](https://hitsz.feishu.cn/share/base/form/shrcna5TjoEOpyrgWCqSt8E34sf)\n",
    "\"\"\"\n",
    "print(summarize_text(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对\"通知内容\"列进行概括"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取CSV文件\n",
    "df = pd.read_csv(\"../data//dates_combined_data.csv\")\n",
    "\n",
    "# 创建一个新列来保存概括的内容\n",
    "df[\"概括内容\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 114/307 [04:38<06:23,  1.99s/it]"
     ]
    }
   ],
   "source": [
    "# 显示进度并更新DataFrame\n",
    "for index, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "    summarized = summarize_text(row[\"通知内容\"])\n",
    "    df.at[index, \"概括内容\"] = summarized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存为新的CSV文件\n",
    "df.to_csv(\"./dates_combined_data_summarized.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bert",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
